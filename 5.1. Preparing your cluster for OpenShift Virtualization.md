## 5.1. Preparing your cluster for OpenShift Virtualization




Review this section before you install OpenShift Virtualization to ensure that your cluster meets the requirements.

Important
You can use any installation method, including user-provisioned, installer-provisioned, or assisted installer, to deploy OpenShift Container Platform. However, the installation method and the cluster topology might affect OpenShift Virtualization functionality, such as snapshots or live migration.



 **Single-node OpenShift differences** 

You can install OpenShift Virtualization on a single-node cluster. See [About single-node OpenShift](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/installing/#install-sno-about-installing-on-a-single-node_install-sno-preparing) for more information. Single-node OpenShift does not support high availability, which results in the following differences:


-  [Pod disruption budgets](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/nodes/#priority-preemption-other_nodes-pods-priority) are not supported.
-  [Live migration](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/virtualization/#virt-live-migration) is not supported.
- Templates or virtual machines that use data volumes or storage profiles must not have the [evictionStrategy](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/virtualization/#virt-configuring-vmi-eviction-strategy) set.


 **FIPS mode** 

If you install your cluster in [FIPS mode](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/installing/#installing-fips-mode_installing-fips) , no additional setup is required for OpenShift Virtualization.


 **IPv6** 

You cannot run OpenShift Virtualization on a single-stack IPv6 cluster. ( [BZ#2193267](https://bugzilla.redhat.com/show_bug.cgi?id=2193267) )


### 5.1.1. Hardware and operating system requirements




Review the following hardware and operating system requirements for OpenShift Virtualization.

 **Supported platforms** 

- On-premise bare metal servers
- Amazon Web Services bare metal instances. See [Deploy OpenShift Virtualization on AWS Bare Metal Nodes](https://access.redhat.com/articles/6409731) for details.
- IBM Cloud Bare Metal Servers. See [Deploy OpenShift Virtualization on IBM Cloud Bare Metal Nodes](https://access.redhat.com/articles/6738731) for details.


Important
Installing OpenShift Virtualization on AWS bare metal instances or on IBM Cloud Bare Metal Servers is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.

For more information about the support scope of Red Hat Technology Preview features, see [Technology Preview Features Support Scope](https://access.redhat.com/support/offerings/techpreview/) .



-  **Bare metal instances or servers offered by other cloud providers are not supported.** 


 **CPU requirements** 

- Supported by Red Hat Enterprise Linux (RHEL) 8
- Support for Intel 64 or AMD64 CPU extensions
- Intel VT or AMD-V hardware virtualization extensions enabled
- NX (no execute) flag enabled


 **Storage requirements** 

- Supported by OpenShift Container Platform


Warning
If you deploy OpenShift Virtualization with Red Hat OpenShift Data Foundation, you must create a dedicated storage class for Windows virtual machine disks. See [Optimizing ODF PersistentVolumes for Windows VMs](https://access.redhat.com/articles/6978371) for details.



 **Operating system requirements** 

- Red Hat Enterprise Linux CoreOS (RHCOS) installed on worker nodes
    
    Note
    RHEL worker nodes are not supported.
    
    
    
    


- If your cluster uses worker nodes with different CPUs, live migration failures can occur because different CPUs have different capabilities. To avoid such failures, use CPUs with appropriate capacity for each node and set node affinity on your virtual machines to ensure successful migration. See [Configuring a required node affinity rule](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/nodes/#nodes-scheduler-node-affinity-configuring-required_nodes-scheduler-node-affinity) for more information.


 **Additional resources** 

-  [About RHCOS](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/architecture/#rhcos-about_architecture-rhcos) .
-  [Red Hat Ecosystem Catalog](https://catalog.redhat.com) for supported CPUs.
-  [Supported storage](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/storage/#storage-overview) .


### 5.1.2. Physical resource overhead requirements




OpenShift Virtualization is an add-on to OpenShift Container Platform and imposes additional overhead that you must account for when planning a cluster. Each cluster machine must accommodate the following overhead requirements in addition to the OpenShift Container Platform requirements. Oversubscribing the physical resources in a cluster can affect performance.

Important
The numbers noted in this documentation are based on Red Hat’s test methodology and setup. These numbers can vary based on your own individual setup and environments.



#### 5.1.2.1. Memory overhead




Calculate the memory overhead values for OpenShift Virtualization by using the equations below.

 **Cluster memory overhead** 

```
Memory overhead per infrastructure node ≈ 150 MiB
```


```
Memory overhead per worker node ≈ 360 MiB
```

Additionally, OpenShift Virtualization environment resources require a total of 2179 MiB of RAM that is spread across all infrastructure nodes.

 **Virtual machine memory overhead** 

```
Memory overhead per virtual machine ≈ (1.002 × requested memory) \
              + 216 MiB \<span id="CO2-1"><!--Empty--></span><span class="callout">1</span>+ 8 MiB × (number of vCPUs) \<span id="CO2-2"><!--Empty--></span><span class="callout">2</span>+ 16 MiB × (number of graphics devices) \<span id="CO2-3"><!--Empty--></span><span class="callout">3</span>+ (additional memory overhead)<span id="CO2-4"><!--Empty--></span><span class="callout">4</span>
```


#### 5.1.2.2. CPU overhead




Calculate the cluster processor overhead requirements for OpenShift Virtualization by using the equation below. The CPU overhead per virtual machine depends on your individual setup.

 **Cluster CPU overhead** 

```
CPU overhead for infrastructure nodes ≈ 4 cores
```


OpenShift Virtualization increases the overall utilization of cluster level services such as logging, routing, and monitoring. To account for this workload, ensure that nodes that host infrastructure components have capacity allocated for 4 additional cores (4000 millicores) distributed across those nodes.

```
CPU overhead for worker nodes ≈ 2 cores + CPU overhead per virtual machine
```

Each worker node that hosts virtual machines must have capacity for 2 additional cores (2000 millicores) for OpenShift Virtualization management workloads in addition to the CPUs required for virtual machine workloads.

 **Virtual machine CPU overhead** 

If dedicated CPUs are requested, there is a 1:1 impact on the cluster CPU overhead requirement. Otherwise, there are no specific rules about how many CPUs a virtual machine requires.


#### 5.1.2.3. Storage overhead




Use the guidelines below to estimate storage overhead requirements for your OpenShift Virtualization environment.

 **Cluster storage overhead** 

```
Aggregated storage overhead per node ≈ 10 GiB
```


10 GiB is the estimated on-disk storage impact for each node in the cluster when you install OpenShift Virtualization.

 **Virtual machine storage overhead** 

Storage overhead per virtual machine depends on specific requests for resource allocation within the virtual machine. The request could be for ephemeral storage on the node or storage resources hosted elsewhere in the cluster. OpenShift Virtualization does not currently allocate any additional ephemeral storage for the running container itself.


#### 5.1.2.4. Example




As a cluster administrator, if you plan to host 10 virtual machines in the cluster, each with 1 GiB of RAM and 2 vCPUs, the memory impact across the cluster is 11.68 GiB. The estimated on-disk storage impact for each node in the cluster is 10 GiB and the CPU impact for worker nodes that host virtual machine workloads is a minimum of 2 cores.

### 5.1.3. Object maximums




You must consider the following tested object maximums when planning your cluster:

-  [OpenShift Container Platform object maximums](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/scalability_and_performance/#planning-your-environment-according-to-object-maximums) .
-  [OpenShift Virtualization object maximums](https://access.redhat.com/articles/6571671) .


### 5.1.4. Restricted network environments




If you install OpenShift Virtualization in a restricted environment with no internet connectivity, you must [configure Operator Lifecycle Manager for restricted networks](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/operators/#olm-restricted-networks) .

If you have limited internet connectivity, you can [configure proxy support in Operator Lifecycle Manager](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/operators/#olm-configuring-proxy-support) to access the Red Hat-provided OperatorHub.

### 5.1.5. Live migration




Live migration has the following requirements:

- Shared storage with `    ReadWriteMany` (RWX) access mode.
- Sufficient RAM and network bandwidth.
- If the virtual machine uses a host model CPU, the nodes must support the virtual machine’s host model CPU.


Note
You must ensure that there is enough memory request capacity in the cluster to support node drains that result in live migrations. You can determine the approximate required spare memory by using the following calculation:

```
Product of (Maximum number of nodes that can drain in parallel) and (Highest total VM memory request allocations across nodes)
```

The default [number of migrations that can run in parallel](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/virtualization/#virt-live-migration-limits) in the cluster is 5.



### 5.1.6. Snapshots and cloning




See [OpenShift Virtualization storage features](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/virtualization/#virt-features-for-storage) for snapshot and cloning requirements.

### 5.1.7. Cluster high-availability options




You can configure one of the following high-availability (HA) options for your cluster:

- Automatic high availability for [installer-provisioned infrastructure](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/installing/#ipi-install-overview) (IPI) is available by deploying [machine health checks](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/machine_management/#machine-health-checks-about_deploying-machine-health-checks) .
    
    Note
    In OpenShift Container Platform clusters installed using installer-provisioned infrastructure and with MachineHealthCheck properly configured, if a node fails the MachineHealthCheck and becomes unavailable to the cluster, it is recycled. What happens next with VMs that ran on the failed node depends on a series of conditions. See [About RunStrategies for virtual machines](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/virtualization/#virt-about-runstrategies-vms_virt-create-vms) for more detailed information about the potential outcomes and how RunStrategies affect those outcomes.
    
    
    
    
- Automatic high availability for both IPI and non-IPI is available by using the [Node Health Check Operator](https://access.redhat.com/documentation/en-us/openshift_container_platform/4.11/html-single/nodes/#node-health-check-operator) on the OpenShift Container Platform cluster to deploy the `    NodeHealthCheck` controller. The controller identifies unhealthy nodes and uses the Self Node Remediation Operator to remediate the unhealthy nodes.
    
    Important
    Node Health Check Operator is a Technology Preview feature only. Technology Preview features are not supported with Red Hat production service level agreements (SLAs) and might not be functionally complete. Red Hat does not recommend using them in production. These features provide early access to upcoming product features, enabling customers to test functionality and provide feedback during the development process.
    
    For more information about the support scope of Red Hat Technology Preview features, see [Technology Preview Features Support Scope](https://access.redhat.com/support/offerings/techpreview/) .
    
    
    
    
- High availability for any platform is available by using either a monitoring system or a qualified human to monitor node availability. When a node is lost, shut it down and run `    oc delete node &lt;lost_node&gt;` .
    
    Note
    Without an external monitoring system or a qualified human monitoring node health, virtual machines lose high availability.
    
    
    
    


